## 卷积






```python

f1 = torch.tensor([[0, -1, 0],
                   [-1, 4, -1],
                   [0, -1, 0]]).float().reshape(1,1,3,3)

f2 = torch.tensor([[-1, -1, -1],
                   [0, 0, 0],
                   [-1, -1, -1]]).float().reshape(1,1,3,3)

f3 = torch.tensor([[2, 0, 0],
                   [0, -1, 0],
                   [0, 0, -1]]).float().reshape(1,1,3,3)

f4 = torch.tensor([[-1, -1, -1],
                   [-1, 8, -1],
                   [-1, -1, -1]]).float().reshape(1,1,3,3)
```







```python
import matplotlib.pyplot as plt
import torch
import torch.nn as nn

p = 'D:/b.jpg'  # 图片路径
im = plt.imread(p)  # 读取
im = im[:, :, 1]  # 灰度矩阵

plt.imshow(im, cmap='gray')  # 显示
plt.show()

s1, s2 = im.shape  # 图像的长宽
im = torch.from_numpy(im).reshape(1, 1, s1, s2).float()  # 把图像矩阵转为tensor

conv_layer = nn.Conv2d(in_channels=1, out_channels=1,
                       stride=1, kernel_size=3, padding=2)  # 初始化一个卷积层
print(conv_layer.weight)  # 打印卷积层的权值

# 自定义卷积核
kernel = torch.tensor([[2, 0, 0],
                       [0, -1, 0],
                       [0, 0, -1]]).float().reshape(1, 1, 3, 3)

conv_layer.weight.data = kernel  # 将先前定义的卷积层里卷积核的权值设置为f1
print(conv_layer.weight)  # 打印卷积层的权值

im = conv_layer(im)  # 对图像进行卷积操作
im = im.squeeze().detach().cpu().numpy()  # 转为array

plt.imshow(im, cmap='gray')  # 显示
plt.show()
```



```python
"""
定义模型
确定损失函数以及优化方法
实现模型训练的过程(前向传播，计算损失，反向传播，更新参数)

处理数据
封装数据
实例化模型
执行训练的过程
测试和验证模型
"""
import torch
import torch.nn as nn
import torch.nn.functional as fn
import torch.optim as optim
import torch.utils.data
import csv
import numpy as np
import random


# 定义模型
class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()

        self.conv1 = nn.Conv2d(in_channels=1,
                               out_channels=10,
                               kernel_size=3,
                               padding=1)

        self.conv2 = nn.Conv2d(in_channels=10,
                               out_channels=20,
                               kernel_size=3,
                               padding=1)

        self.pooling = nn.MaxPool2d(kernel_size=2, stride=2)

        self.l1 = nn.Linear(20 * 7 * 7, 512)
        self.l2 = nn.Linear(512, 256)
        self.l3 = nn.Linear(256, 10)
        self.activate = nn.Sigmoid()

    def forward(self, x):
        out = self.activate(self.pooling(self.conv1(x)))
        out = self.activate(self.pooling(self.conv2(out)))
        out = out.view(x.size(0), -1)
        out = self.activate(self.l1(out))
        out = self.activate(self.l2(out))
        out = self.activate(self.l3(out))

        return out


def training(model, loader, opt, epochs):
    for epoch in range(epochs):
        total_loss = 0
        for x, y in loader:
            # 梯度清零
            opt.zero_grad()

            # 前向传播
            y_ = model(x)
            y_ = y_.squeeze()  # 去掉多余的维度

            # 计算损失
            loss = fn.cross_entropy(y_, y, reduction='sum')
            total_loss += loss

            # 反向传播
            loss.backward()

            # 更新模型参数
            opt.step()

        total_loss = total_loss / len(loader.dataset)
        print(total_loss.item())


if __name__ == '__main__':
    p = r'C:\Users\Guppy\Documents\GitHub\DeepLearningNotebook\datasets\mnist\mnist.csv'

    with open(p, 'r') as f:  # 读取csv文件
        data = list(csv.reader(f))  # 读文件并保存为列表
        data = data[1::]  # 全部数据，取第二行到最后一行，跳过第一行的标题
        data = np.array(data, dtype=np.float)  # 把数据转为array

    # 划分数据集
    rate_of_train = 0.8  # 训练样本占比
    n_of_train = int(rate_of_train * len(data))  # 训练样本数目
    data_train = data[0:n_of_train]  # 训练集
    data_test = data[n_of_train::]  # 测试集

    x_train = data_train[:, 1::] / 255
    y_train = data_train[:, 0]

    x_train = torch.from_numpy(x_train).float()  # array转为tensor
    x_train = x_train.view(-1, 1, 28, 28)  # 改变形状为 [样本数，通道数，长，宽]
    y_train = torch.from_numpy(y_train).long()
    ds = torch.utils.data.TensorDataset(x_train, y_train)  # 封装为TensorDataset
    loader = torch.utils.data.DataLoader(ds, batch_size=100)  # 封装为DataLoader

    # 模型初始化
    model = CNN()
    # 优化器初始化
    opt = optim.Adam(params=model.parameters(), lr=0.001)
    # 执行训练过程
    training(model=model, loader=loader, opt=opt, epochs=10)

    # 测试模型
    x_test = data_test[:, 1::] / 255
    y_test = data_test[:, 0]

    x_test = torch.from_numpy(x_test).float()  # array转tensor
    x_test = x_test.view(-1, 1, 28, 28)  # 改变形状为 [样本数，通道数，长，宽]
    y_test = torch.from_numpy(y_test).long()  # array转tensor

    y_predict = model(x_test)  # 模型输出
    y_predict = y_predict.squeeze()

    prediction = torch.argmax(y_predict, 1)  # 模型预测的标签
    correct = (prediction == y_test).sum().float()  # 统计模型预测标签等于目标标签的数目
    accuracy = correct / y_test.size(0)  # 计算准确率
    print('测试准确率为: {}'.format(accuracy.item()))

    loss = fn.cross_entropy(y_predict, y_test)
    print('测试损失为: {}'.format(loss.item()))

```







