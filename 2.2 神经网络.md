



## 常见激活函数







sigmoid
$$
sigmoid(x) = \frac{1}{1+e^{-x}}
$$




tanh


$$
tanh(x) = 2sigmoid(2x)-1 \\
= \frac{1 - e^{-2x}}{1+e^{-2x}}
$$




ReLU


$$
ReLU(x) = max(x,0)
$$




## 矩阵乘法







## 查看pytorch中神经网络的参数



```
model.layer.weight
model.layer.bias
for name, p in model.named_parameters():
    print(name)
    print(p)
```

```
model.layer3.weight
```



## pytorch模型的保存和加载



```python
state = {'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epochs': epoch}
torch.save(state, 'record/{}-{:04d}-{:.4f}.pth'.format('nnlm', epoch, train_loss))
```

```python
checkpoint = torch.load(path_of_model)
m.load_state_dict(checkpoint['model'])
opt.load_state_dict(checkpoint['optimizer'])
```

归一化

r方



## 练手

diabetes.csv是一个糖尿病的数据集，主要包括442行数据，10个属性值，分别是：Age(年龄)、性别(Sex)、Body mass index(体质指数)、Average Blood Pressure(平均血压)、S1~S6一年后疾病级数指标。Target为一年后患疾病的定量指标。这10个特征中的每个特征都已经被处理成0均值，方差归一化的特征值。





```python
"""
定义模型
确定损失函数以及优化方法
实现模型训练的过程(前向传播，计算损失，反向传播，更新参数)

处理数据
封装数据
实例化模型
执行训练的过程
测试和验证模型
"""
import torch
import torch.nn as nn
import torch.nn.functional as fn
import torch.optim as optim
import torch.utils.data
import csv
import numpy as np
import random


# 定义模型
class NN(nn.Module):
    def __init__(self):
        super(NN, self).__init__()

        self.l1 = nn.Linear(13, 32)
        self.l2 = nn.Linear(32, 32)
        self.l3 = nn.Linear(32, 1)
        self.activate = nn.Sigmoid()

    def forward(self, x):
        out = self.activate(self.l1(x))
        out = self.activate(self.l2(out))
        out = self.l3(out)

        return out


def training(model, loader, opt, epochs):
    for epoch in range(epochs):
        total_loss = 0
        for x, y in loader:
            # 梯度清零
            opt.zero_grad()

            # 前向传播
            y_ = model(x)
            y_ = y_.squeeze()  # 去掉多余的维度

            # 计算损失
            loss = fn.mse_loss(y_, y, reduction='sum')
            total_loss += loss

            # 反向传播
            loss.backward()

            # 更新模型参数
            opt.step()

        total_loss = total_loss / len(loader.dataset)
        print(total_loss.item())


if __name__ == '__main__':
    path = 'D:/boston.csv'
    with open(path, 'r') as f:
        data = list(csv.reader(f))[1::]
        random.shuffle(data)  # 乱序
        data = np.array(data, dtype=np.float)

    # 划分数据集
    rate_of_train = 0.8  # 训练样本占比
    n_of_train = int(rate_of_train * len(data))  # 训练样本数目
    data_train = data[0:n_of_train]  # 训练集
    data_test = data[n_of_train::]  # 测试集

    x_train = data_train[:, 1::]
    y_train = data_train[:, 0]
    # print(data[0:5])

    x_train = torch.from_numpy(x_train).float()  # array转为tensor
    y_train = torch.from_numpy(y_train).float()
    ds = torch.utils.data.TensorDataset(x_train, y_train)  # 封装为TensorDataset
    loader = torch.utils.data.DataLoader(ds, batch_size=100)  # 封装为DataLoader

    # 模型初始化
    model = NN()
    # 优化器初始化
    opt = optim.Adam(params=model.parameters(), lr=0.01)
    # 执行训练过程
    training(model=model, loader=loader, opt=opt, epochs=300)

    # 测试模型
    x_test = data_test[:, 1::]
    y_test = data_test[:, 0]

    x_test = torch.from_numpy(x_test).float()
    y_test = torch.from_numpy(y_test).float()

    y_predict = model(x_test)
    y_predict = y_predict.squeeze()

    loss = fn.mse_loss(y_predict, y_test)
    print('the loss on test data is {}'.format(loss.item()))


```

