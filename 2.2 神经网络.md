## 常见激活函数

激活函数为神经网络引入非线性能力

sigmoid
$$
sigmoid(x) = \frac{1}{1+e^{-x}}
$$


tanh


$$
tanh(x) = 2sigmoid(2x)-1 \\
= \frac{1 - e^{-2x}}{1+e^{-2x}}
$$


ReLU


$$
ReLU(x) = max(x,0)
$$



```python
import torch
import torch.nn as nn
import matplotlib.pyplot as plt

f1 = nn.Sigmoid()
f2 = nn.ReLU()
f3 = nn.Tanh()
f4 = nn.LeakyReLU()

x = torch.arange(-5, 5, step=0.1)
print(x)
y = f4(x)

x = x.detach().cpu().numpy()
y = y.detach().cpu().numpy()
plt.plot([-5, 5], [0, 0], c='black')  # x轴
plt.plot([0, 0], [-1, 1], c='black')  # y轴
plt.plot(x, y)  # 激活函数的曲线
plt.show()
```




## 矩阵乘法











## 查看pytorch中神经网络的参数



```
model.layer.weight
model.layer.bias
for name, p in model.named_parameters():
    print(name)
    print(p)
```

```
model.layer3.weight
```





```python
import torch
import torch.nn as nn
import matplotlib.pyplot as plt

l = nn.Linear(2, 1)

a = torch.tensor([[1, 2]]).float()
y = l(a)

print(y)

w = l.weight.data
b = l.bias.data
print(torch.mm(a, w.t()) + b)


a = torch.tensor([[-1, 1]]).float()

print(a)
print(l.weight.data)
print(l.bias.data)

print(l(a))
print(torch.mm(a, l.weight.data.t()) + l.bias.data)
```





## pytorch模型的保存和加载



```python
state = {'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epochs': epoch}
torch.save(state, 'record/{}-{:04d}-{:.4f}.pth'.format('nnlm', epoch, train_loss))
```

```python
checkpoint = torch.load(path_of_model)
m.load_state_dict(checkpoint['model'])
opt.load_state_dict(checkpoint['optimizer'])
```



## 归一化

线性函数归一化(Min-Max scaling)

零均值标准化(Z-score standardization)





## R方

是一个评价拟合好坏的指标。越接近于1，则拟合回归效果越好。


$$
R^2 = 1 - \frac{\sum (y_i - \hat{y}_i)^2 }{\sum (y_i - \overline{y})^2}
$$



```
    def r_2(y_real, y_predict):
        y_bar = np.mean(y_real)
        
        a = np.sum((y_real - y_predict)**2)
        b = np.sum((y_real - y_bar)**2)
        
        return 1 - a / b
```






## diabetes数据集练手

diabetes.csv是一个糖尿病的数据集，主要包括442行数据，10个属性值，分别是：Age(年龄)、性别(Sex)、Body mass index(体质指数)、Average Blood Pressure(平均血压)、S1~S6一年后疾病级数指标。Target为一年后患疾病的定量指标。这10个特征中的每个特征都已经被处理成0均值，方差归一化的特征值。



1. 正确地读入数据，并划分好训练集和测试集

2. 调整修改模型结构和参数，让模型在测试集上取得较好的r方。

   

## Boston数据集练手

```python
"""
定义模型
确定损失函数以及优化方法
实现模型训练的过程(前向传播，计算损失，反向传播，更新参数)

处理数据
封装数据
实例化模型
执行训练的过程
测试和验证模型
"""
import torch
import torch.nn as nn
import torch.nn.functional as fn
import torch.optim as optim
import torch.utils.data
import csv
import numpy as np
import random


# 定义模型
class NN(nn.Module):
    def __init__(self):
        super(NN, self).__init__()

        self.l1 = nn.Linear(13, 32)
        self.l2 = nn.Linear(32, 32)
        self.l3 = nn.Linear(32, 1)
        self.activate = nn.Sigmoid()

    def forward(self, x):
        out = self.activate(self.l1(x))
        out = self.activate(self.l2(out))
        out = self.l3(out)

        return out


def training(model, loader, opt, epochs):
    for epoch in range(epochs):
        total_loss = 0
        for x, y in loader:
            # 梯度清零
            opt.zero_grad()

            # 前向传播
            y_ = model(x)
            y_ = y_.squeeze()  # 去掉多余的维度

            # 计算损失
            loss = fn.mse_loss(y_, y, reduction='sum')
            total_loss += loss

            # 反向传播
            loss.backward()

            # 更新模型参数
            opt.step()

        total_loss = total_loss / len(loader.dataset)
        print(total_loss.item())


if __name__ == '__main__':
    path = 'D:/boston.csv'
    with open(path, 'r') as f:
        data = list(csv.reader(f))[1::]
        random.shuffle(data)  # 乱序
        data = np.array(data, dtype=np.float)

    # 划分数据集
    rate_of_train = 0.8  # 训练样本占比
    n_of_train = int(rate_of_train * len(data))  # 训练样本数目
    data_train = data[0:n_of_train]  # 训练集
    data_test = data[n_of_train::]  # 测试集

    x_train = data_train[:, 1::]
    y_train = data_train[:, 0]
    # print(data[0:5])

    x_train = torch.from_numpy(x_train).float()  # array转为tensor
    y_train = torch.from_numpy(y_train).float()
    ds = torch.utils.data.TensorDataset(x_train, y_train)  # 封装为TensorDataset
    loader = torch.utils.data.DataLoader(ds, batch_size=100)  # 封装为DataLoader

    # 模型初始化
    model = NN()
    # 优化器初始化
    opt = optim.Adam(params=model.parameters(), lr=0.01)
    # 执行训练过程
    training(model=model, loader=loader, opt=opt, epochs=300)

    # 测试模型
    x_test = data_test[:, 1::]
    y_test = data_test[:, 0]

    x_test = torch.from_numpy(x_test).float()
    y_test = torch.from_numpy(y_test).float()

    y_predict = model(x_test)
    y_predict = y_predict.squeeze()

    loss = fn.mse_loss(y_predict, y_test)
    print('the loss on test data is {}'.format(loss.item()))


```



## 总结

神经网络通过前向传播计算出输出。

用损失函数评价输出和标签的差异。

用学习算法（梯度下降等）去找到合适的权值和偏置，使得损失函数的值最小。

用反向传播来计算梯度。